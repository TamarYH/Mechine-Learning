{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "initial_id",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "\n",
    "# sqldf(\"\"\"\n",
    "# SELECT * \n",
    "# FROM df\n",
    "# LIMIT 5\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "960a1dff1d45e178",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'/Users/maya/Documents/Information Systems/שנה ג׳/למידת מכונה/פרוייקט קורס/XY_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0557f07a-c94d-4fbe-9488-80325753cf1d",
   "metadata": {},
   "source": [
    "# Feature extraction ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7344ddcc-fe50-465d-80ac-e7e9ef2aa8b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message_date</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>previous_messages_dates</th>\n",
       "      <th>date_of_new_follower</th>\n",
       "      <th>date_of_new_follow</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>email_verified</th>\n",
       "      <th>blue_tick</th>\n",
       "      <th>embedded_content</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b8f4e560fa</td>\n",
       "      <td>but yeah i like purple maybe thats why!! ;)  ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2023-10-2 7:41:52</td>\n",
       "      <td>2015-4-13 0:1:16</td>\n",
       "      <td>[2019-2-15 16:12:42, 2020-6-2 16:49:53, 2021-4...</td>\n",
       "      <td>[2016-1-13 7:12:26, 2016-5-17 13:40:38, 2016-1...</td>\n",
       "      <td>[2016-7-15 0:3:50, 2016-4-10 22:31:8, 2016-10-...</td>\n",
       "      <td>ClareRosindill3265@messenger.gov</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>mp4</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f81a1511b2</td>\n",
       "      <td>_Henrie haha i WISH i coudl meet you.. you sho...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-11-17 2:1:57</td>\n",
       "      <td>2013-7-1 18:58:16</td>\n",
       "      <td>[2021-7-5 21:53:48, 2020-12-12 9:7:50, 2020-9-...</td>\n",
       "      <td>[2016-10-4 7:49:46, 2016-6-10 7:47:39, 2016-4-...</td>\n",
       "      <td>[2016-7-5 20:23:57, 2016-5-3 15:9:51, 2018-11-...</td>\n",
       "      <td>ErenaAntonchik231@messenger.gov</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>tiktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3e9e3f0d69</td>\n",
       "      <td>nah, you`re just altered forever   Enjoy.</td>\n",
       "      <td>positive</td>\n",
       "      <td>2022-6-1 6:53:18</td>\n",
       "      <td>2013-8-8 2:21:12</td>\n",
       "      <td>[2021-7-11 9:59:36, 2020-2-18 6:38:45, 2021-5-...</td>\n",
       "      <td>[2018-7-13 17:0:3, 2016-2-13 17:8:12, 2016-2-1...</td>\n",
       "      <td>[2016-7-9 22:15:10, 2018-4-13 20:37:55, 2016-1...</td>\n",
       "      <td>GodardCowlas6687@api.gov</td>\n",
       "      <td>F</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>tiktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a068b95bd9</td>\n",
       "      <td>Can you ask Ryan why he stopped following me ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2022-1-4 11:38:57</td>\n",
       "      <td>2015-10-16 14:51:19</td>\n",
       "      <td>[2021-8-16 4:55:32, 2021-6-1 10:13:37, 2021-12...</td>\n",
       "      <td>[2018-7-1 5:9:39]</td>\n",
       "      <td>[2018-10-18 7:23:20, 2018-4-10 12:17:6, 2016-6...</td>\n",
       "      <td>RalfStolberger6467@python.gov</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>mp4</td>\n",
       "      <td>tiktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e6da2d1835</td>\n",
       "      <td>New issue of  in the office...desperately want...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2022-5-11 21:56:27</td>\n",
       "      <td>2013-12-15 19:8:40</td>\n",
       "      <td>[2021-9-11 10:55:6, 2021-5-6 12:1:54, 2021-1-1...</td>\n",
       "      <td>[2018-11-2 11:16:12, 2018-10-18 16:8:34]</td>\n",
       "      <td>[2018-4-18 20:56:34, 2018-7-1 14:56:33, 2016-4...</td>\n",
       "      <td>MadelLeaton248@bbc.gov.il</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  b8f4e560fa   but yeah i like purple maybe thats why!! ;)  ...  positive   \n",
       "1  f81a1511b2  _Henrie haha i WISH i coudl meet you.. you sho...  positive   \n",
       "2  3e9e3f0d69          nah, you`re just altered forever   Enjoy.  positive   \n",
       "3  a068b95bd9   Can you ask Ryan why he stopped following me ...  negative   \n",
       "4  e6da2d1835  New issue of  in the office...desperately want...  negative   \n",
       "\n",
       "         message_date account_creation_date  \\\n",
       "0   2023-10-2 7:41:52      2015-4-13 0:1:16   \n",
       "1   2022-11-17 2:1:57     2013-7-1 18:58:16   \n",
       "2    2022-6-1 6:53:18      2013-8-8 2:21:12   \n",
       "3   2022-1-4 11:38:57   2015-10-16 14:51:19   \n",
       "4  2022-5-11 21:56:27    2013-12-15 19:8:40   \n",
       "\n",
       "                             previous_messages_dates  \\\n",
       "0  [2019-2-15 16:12:42, 2020-6-2 16:49:53, 2021-4...   \n",
       "1  [2021-7-5 21:53:48, 2020-12-12 9:7:50, 2020-9-...   \n",
       "2  [2021-7-11 9:59:36, 2020-2-18 6:38:45, 2021-5-...   \n",
       "3  [2021-8-16 4:55:32, 2021-6-1 10:13:37, 2021-12...   \n",
       "4  [2021-9-11 10:55:6, 2021-5-6 12:1:54, 2021-1-1...   \n",
       "\n",
       "                                date_of_new_follower  \\\n",
       "0  [2016-1-13 7:12:26, 2016-5-17 13:40:38, 2016-1...   \n",
       "1  [2016-10-4 7:49:46, 2016-6-10 7:47:39, 2016-4-...   \n",
       "2  [2018-7-13 17:0:3, 2016-2-13 17:8:12, 2016-2-1...   \n",
       "3                                  [2018-7-1 5:9:39]   \n",
       "4           [2018-11-2 11:16:12, 2018-10-18 16:8:34]   \n",
       "\n",
       "                                  date_of_new_follow  \\\n",
       "0  [2016-7-15 0:3:50, 2016-4-10 22:31:8, 2016-10-...   \n",
       "1  [2016-7-5 20:23:57, 2016-5-3 15:9:51, 2018-11-...   \n",
       "2  [2016-7-9 22:15:10, 2018-4-13 20:37:55, 2016-1...   \n",
       "3  [2018-10-18 7:23:20, 2018-4-10 12:17:6, 2016-6...   \n",
       "4  [2018-4-18 20:56:34, 2018-7-1 14:56:33, 2016-4...   \n",
       "\n",
       "                              email gender email_verified blue_tick  \\\n",
       "0  ClareRosindill3265@messenger.gov      F            NaN     False   \n",
       "1   ErenaAntonchik231@messenger.gov      M           True      True   \n",
       "2          GodardCowlas6687@api.gov      F           True      True   \n",
       "3     RalfStolberger6467@python.gov      M          False     False   \n",
       "4         MadelLeaton248@bbc.gov.il      M          False     False   \n",
       "\n",
       "  embedded_content  platform  \n",
       "0              mp4  facebook  \n",
       "1            False    tiktok  \n",
       "2            False    tiktok  \n",
       "3              mp4    tiktok  \n",
       "4             None      None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "26ea6bab-0493-4955-973c-b4e82826539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is edu suffix or not\n",
    "df['is_edu'] = df.email.str.find('edu') != -1\n",
    "\n",
    "# Is a man or woman\n",
    "df['is_man'] = df.gender == 'M'\n",
    "\n",
    "# Is the email verified \n",
    "df['is_email_verified'] = df['email_verified'] == True\n",
    "\n",
    "# Does the account have a blue tick\n",
    "df['is_blue_tick'] = df['blue_tick'] == True\n",
    "\n",
    "# Is embeded content (mp4 or link)\n",
    "embeded_content_dummies = pd.get_dummies(df.embedded_content)[['link','mp4']].rename(columns={'link':'is_link','mp4':'is_mp4'})\n",
    "df = pd.concat([df,embeded_content_dummies],axis=1)\n",
    "\n",
    "# Platform (Instagram or Telegram)\n",
    "platform_dummies = pd.get_dummies(df.platform)[['instagram','telegram']].rename(columns={'instagram':'is_instagram','telegram':'is_telegram'})\n",
    "df = pd.concat([df,platform_dummies],axis=1)\n",
    "\n",
    "################## Chane Y variable to Boolean ##################\n",
    "df['is_positive_sentiment'] = df_for_model_for_mode['sentiment'] == 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed51f4e7-cb18-400b-86e4-fb8920c97e12",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tenure_days'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:153\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:182\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'tenure_days'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 14\u001B[0m\n\u001B[1;32m      6\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtenure\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage_date\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m-\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccount_creation_date\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Add the value of the sentiment to the DataFrame\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Assuming the sentiment is already present in the DataFrame as 'sentiment'\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# If not, you can add it from your source\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# For example, if 'sentiment' is stored in a separate pickle file\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# sentiment_df = pd.read_pickle('path_to_sentiment_file.pkl')\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# df['sentiment'] = sentiment_df['sentiment']\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtenure_years\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtenure_days\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m365.25\u001B[39m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Display the DataFrame with tenure and sentiment\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(df[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage_date\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccount_creation_date\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtenure\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m]])\n",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4088\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4089\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4090\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4092\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3809\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3805\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3806\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3807\u001B[0m     ):\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3809\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3810\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3811\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3812\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'tenure_days'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert 'message_date' and 'account_creation_date' columns to datetime objects\n",
    "df['message_date'] = pd.to_datetime(df['message_date'])\n",
    "df['account_creation_date'] = pd.to_datetime(df['account_creation_date'])\n",
    "\n",
    "# Calculate tenure by subtracting account_creation_date from message_date\n",
    "df['tenure'] = df['message_date'] - df['account_creation_date']\n",
    "\n",
    "# Add the value of the sentiment to the DataFrame\n",
    "# Assuming the sentiment is already present in the DataFrame as 'sentiment'\n",
    "# If not, you can add it from your source\n",
    "# For example, if 'sentiment' is stored in a separate pickle file\n",
    "# sentiment_df = pd.read_pickle('path_to_sentiment_file.pkl')\n",
    "# df['sentiment'] = sentiment_df['sentiment']\n",
    "df['tenure_years'] = df['tenure_days'] / 365.25\n",
    "\n",
    "# Display the DataFrame with tenure and sentiment\n",
    "print(df[['message_date', 'account_creation_date', 'tenure', 'sentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3059a5-9675-424c-959f-2cc8046f69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have pandas imported and your DataFrame is loaded\n",
    "# df = pd.read_pickle(r'/Users/maya/Documents/Information Systems/שנה ג׳/למידת מכונה/פרוייקט קורס/XY_train.pkl')\n",
    "\n",
    "# List of binary columns\n",
    "binary_columns = ['email', 'gender', 'email_verified', 'blue_tick', 'embedded_content', 'platform']\n",
    "\n",
    "# Create dummy variables for binary columns\n",
    "dummy_df = pd.get_dummies(df[binary_columns], columns=binary_columns)\n",
    "\n",
    "# Concatenate dummy variables with sentiment column\n",
    "dummy_df['sentiment'] = df['sentiment']\n",
    "\n",
    "# Perform cross-tabulation\n",
    "result_df = pd.crosstab(index=[dummy_df[col] for col in dummy_df.columns], columns=dummy_df['sentiment'])\n",
    "\n",
    "# Add 'total' row and column\n",
    "result_df['total'] = result_df.sum(axis=1)\n",
    "result_df.loc['total'] = result_df.sum()\n",
    "\n",
    "# Rename the index levels and columns\n",
    "result_df.index.names = [col.replace('_', '') for col in dummy_df.columns]\n",
    "result_df.columns = ['false', 'true', 'total']\n",
    "\n",
    "# Reset index to convert index levels to columns\n",
    "result_df.reset_index(inplace=True)\n",
    "\n",
    "# Display the result DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e15d7da5-097f-4bc2-b089-2529b8cc3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features_list = ['textID','is_edu', 'is_man', \n",
    "                       'is_email_verified', 'is_blue_tick',\n",
    "                       'is_link','is_mp4', 'is_positive_sentiment',\n",
    "                       'is_instagram','is_telegram']\n",
    "\n",
    "df_for_model = df[model_features_list].set_index('textID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "85c6e2be-800f-412a-9626-3b293ef83afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_edu</th>\n",
       "      <th>is_man</th>\n",
       "      <th>is_email_verified</th>\n",
       "      <th>is_blue_tick</th>\n",
       "      <th>is_link</th>\n",
       "      <th>is_link</th>\n",
       "      <th>is_mp4</th>\n",
       "      <th>is_mp4</th>\n",
       "      <th>is_positive_sentiment</th>\n",
       "      <th>is_instagram</th>\n",
       "      <th>is_instagram</th>\n",
       "      <th>is_telegram</th>\n",
       "      <th>is_telegram</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b8f4e560fa</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f81a1511b2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3e9e3f0d69</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a068b95bd9</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e6da2d1835</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35ee036565</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10c23a0f46</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2dd416423</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d9f7bd1045</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33b4f870e8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12272 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            is_edu  is_man  is_email_verified  is_blue_tick  is_link  is_link  \\\n",
       "textID                                                                          \n",
       "b8f4e560fa   False   False              False         False    False    False   \n",
       "f81a1511b2   False    True               True          True    False    False   \n",
       "3e9e3f0d69   False   False               True          True    False    False   \n",
       "a068b95bd9   False    True              False         False    False    False   \n",
       "e6da2d1835   False    True              False         False    False    False   \n",
       "...            ...     ...                ...           ...      ...      ...   \n",
       "35ee036565   False   False              False         False    False    False   \n",
       "10c23a0f46   False   False               True          True    False    False   \n",
       "a2dd416423   False   False               True         False     True     True   \n",
       "d9f7bd1045   False    True              False         False    False    False   \n",
       "33b4f870e8    True   False              False          True    False    False   \n",
       "\n",
       "            is_mp4  is_mp4  is_positive_sentiment  is_instagram  is_instagram  \\\n",
       "textID                                                                          \n",
       "b8f4e560fa    True    True                   True         False         False   \n",
       "f81a1511b2   False   False                   True         False         False   \n",
       "3e9e3f0d69   False   False                   True         False         False   \n",
       "a068b95bd9    True    True                  False         False         False   \n",
       "e6da2d1835   False   False                  False         False         False   \n",
       "...            ...     ...                    ...           ...           ...   \n",
       "35ee036565   False   False                   True         False         False   \n",
       "10c23a0f46   False   False                   True         False         False   \n",
       "a2dd416423   False   False                  False         False         False   \n",
       "d9f7bd1045   False   False                  False          True          True   \n",
       "33b4f870e8   False   False                   True         False         False   \n",
       "\n",
       "            is_telegram  is_telegram  \n",
       "textID                                \n",
       "b8f4e560fa        False        False  \n",
       "f81a1511b2        False        False  \n",
       "3e9e3f0d69        False        False  \n",
       "a068b95bd9        False        False  \n",
       "e6da2d1835        False        False  \n",
       "...                 ...          ...  \n",
       "35ee036565        False        False  \n",
       "10c23a0f46        False        False  \n",
       "a2dd416423         True         True  \n",
       "d9f7bd1045        False        False  \n",
       "33b4f870e8        False        False  \n",
       "\n",
       "[12272 rows x 13 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "003a04fa-fe29-49fb-8102-3ba26609a541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7307535641547862\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume df_for_model is your pandas DataFrame with X variables and the target variable 'is_positive_sentiment'\n",
    "\n",
    "# Step 1: Split the data into features (X) and target variable (y)\n",
    "X = df_for_model.drop('is_positive_sentiment', axis=1)\n",
    "y = df_for_model['is_positive_sentiment']\n",
    "\n",
    "# Step 2: Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Import the logistic regression model\n",
    "# Already imported in the previous step\n",
    "\n",
    "# Step 4: Train the logistic regression model\n",
    "logistic_regression_model = LogisticRegression()\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = logistic_regression_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9a0f7c77-c941-4c16-b7be-7137773bd489",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[150], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m X \u001B[38;5;241m=\u001B[39m sm\u001B[38;5;241m.\u001B[39madd_constant(X)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Step 3: Create and fit the logistic regression model\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m logit_model \u001B[38;5;241m=\u001B[39m \u001B[43msm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLogit\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m logit_result \u001B[38;5;241m=\u001B[39m logit_model\u001B[38;5;241m.\u001B[39mfit()\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Step 4: Get summary of the model\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:475\u001B[0m, in \u001B[0;36mBinaryModel.__init__\u001B[0;34m(self, endog, exog, offset, check_rank, **kwargs)\u001B[0m\n\u001B[1;32m    472\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, endog, exog, offset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_rank\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    473\u001B[0m     \u001B[38;5;66;03m# unconditional check, requires no extra kwargs added by subclasses\u001B[39;00m\n\u001B[1;32m    474\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_kwargs(kwargs)\n\u001B[0;32m--> 475\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_rank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    477\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, MultinomialModel):\n\u001B[1;32m    478\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mendog \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m&\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mendog \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m)):\n",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:185\u001B[0m, in \u001B[0;36mDiscreteModel.__init__\u001B[0;34m(self, endog, exog, check_rank, **kwargs)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, endog, exog, check_rank\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_rank \u001B[38;5;241m=\u001B[39m check_rank\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraise_on_perfect_prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# keep for backwards compat\u001B[39;00m\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_extra \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/statsmodels/base/model.py:270\u001B[0m, in \u001B[0;36mLikelihoodModel.__init__\u001B[0;34m(self, endog, exog, **kwargs)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, endog, exog\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 270\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minitialize()\n",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/statsmodels/base/model.py:95\u001B[0m, in \u001B[0;36mModel.__init__\u001B[0;34m(self, endog, exog, **kwargs)\u001B[0m\n\u001B[1;32m     93\u001B[0m missing \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmissing\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     94\u001B[0m hasconst \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhasconst\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m---> 95\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhasconst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m                              \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_constant \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mk_constant\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexog \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mexog\n",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/statsmodels/base/model.py:135\u001B[0m, in \u001B[0;36mModel._handle_data\u001B[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_handle_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, endog, exog, missing, hasconst, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 135\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mhandle_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhasconst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001B[39;00m\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m kwargs:\n",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/statsmodels/base/data.py:675\u001B[0m, in \u001B[0;36mhandle_data\u001B[0;34m(endog, exog, missing, hasconst, **kwargs)\u001B[0m\n\u001B[1;32m    672\u001B[0m     exog \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(exog)\n\u001B[1;32m    674\u001B[0m klass \u001B[38;5;241m=\u001B[39m handle_data_class_factory(endog, exog)\n\u001B[0;32m--> 675\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mklass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mendog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexog\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexog\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhasconst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhasconst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m             \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/statsmodels/base/data.py:88\u001B[0m, in \u001B[0;36mModelData.__init__\u001B[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconst_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk_constant \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 88\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_constant\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhasconst\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_integrity()\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cache \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[0;32m~/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/statsmodels/base/data.py:133\u001B[0m, in \u001B[0;36mModelData._handle_constant\u001B[0;34m(self, hasconst)\u001B[0m\n\u001B[1;32m    131\u001B[0m check_implicit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    132\u001B[0m exog_max \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexog, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misfinite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexog_max\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mall():\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MissingDataError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexog contains inf or nans\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    135\u001B[0m exog_min \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexog, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Given Pandas DataFrame\n",
    "# Assume df is your pandas DataFrame with X variables and the target variable 'is_positive_sentiment'\n",
    "\n",
    "# Step 1: Split the data into features (X) and target variable (y)\n",
    "X = df[['is_edu', 'is_man', 'is_email_verified', 'is_blue_tick', 'is_link', 'is_mp4', 'is_instagram', 'is_telegram']]\n",
    "y = df['is_positive_sentiment']\n",
    "\n",
    "# Step 2: Add constant to the features (X) - this is required for statsmodels\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Step 3: Create and fit the logistic regression model\n",
    "logit_model = sm.Logit(y.values, X.values)\n",
    "logit_result = logit_model.fit()\n",
    "\n",
    "# Step 4: Get summary of the model\n",
    "print(logit_result.summary())\n",
    "\n",
    "# Step 5: Check p-values and eliminate non-significant variables\n",
    "significant_vars = logit_result.pvalues[logit_result.pvalues < 0.05].index\n",
    "X_significant = X[significant_vars]\n",
    "\n",
    "# Step 6: Refit the logistic regression model with significant variables\n",
    "logit_model_significant = sm.Logit(y, X_significant)\n",
    "logit_result_significant = logit_model_significant.fit()\n",
    "\n",
    "# Step 7: Get summary of the new model with significant variables\n",
    "print(logit_result_significant.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1f6d2b61-8445-4913-8f4c-29b9f17f8ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12272, 13)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d925b-eaf6-4f94-8d45-f787f343cc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd9dc379-9c0b-4932-8381-5d36002c54a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     but yeah i like purple maybe thats why!! ;)  ...\n",
       "1    _Henrie haha i WISH i coudl meet you.. you sho...\n",
       "2            nah, you`re just altered forever   Enjoy.\n",
       "3     Can you ask Ryan why he stopped following me ...\n",
       "4    New issue of  in the office...desperately want...\n",
       "5                    very very cute  and fun to watch.\n",
       "6      Enjoy...wish I was there! Nice day in Spring...\n",
       "7     Sadly, all I have is the Stanley Steemer 800 ...\n",
       "8                       you are disappointing me......\n",
       "9                               yes! fb, ah i miss you\n",
       "dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame.from_dict(df['text'][:10].to_dict())\n",
    "\n",
    "pd.Series({0: ' but yeah i like purple maybe thats why!! ;)  :p :d',\n",
    " 1: '_Henrie haha i WISH i coudl meet you.. you should stop by seattle some time  home of the STARBUKS ;) I LOVE YOU DAVID!!',\n",
    " 2: ' nah, you`re just altered forever   Enjoy.',\n",
    " 3: ' Can you ask Ryan why he stopped following me on Twitter',\n",
    " 4: 'New issue of  in the office...desperately want to flick through but have so much to do. It`ll have to wait',\n",
    " 5: ' very very cute  and fun to watch.',\n",
    " 6: '  Enjoy...wish I was there! Nice day in Springfield today..however I have my end of month expense report to do',\n",
    " 7: ' Sadly, all I have is the Stanley Steemer 800 number.',\n",
    " 8: '  you are disappointing me......',\n",
    " 9: ' yes! fb, ah i miss you'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675443e9-b032-494a-94b8-fa31ea1d68fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "766aa2aa2655d69c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
