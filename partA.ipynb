{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af32a0ee5407dc8b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-20T14:35:52.518517Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33m[W 2024-02-20 16:35:53.527 ServerApp]\u001B[m A `_jupyter_server_extension_points` function was not found in notebook_shim. Instead, a `_jupyter_server_extension_paths` function was found and will be used for now. This function name will be deprecated in future releases of Jupyter Server.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.528 ServerApp]\u001B[m jupyter_lsp | extension was successfully linked.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.532 ServerApp]\u001B[m jupyter_server_terminals | extension was successfully linked.\r\n",
      "\u001B[33m[W 2024-02-20 16:35:53.534 LabApp]\u001B[m 'iopub_data_rate_limit' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\r\n",
      "\u001B[33m[W 2024-02-20 16:35:53.538 ServerApp]\u001B[m ServerApp.iopub_data_rate_limit config is deprecated in 2.0. Use ZMQChannelsWebsocketConnection.iopub_data_rate_limit.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.538 ServerApp]\u001B[m jupyterlab | extension was successfully linked.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.542 ServerApp]\u001B[m notebook | extension was successfully linked.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.808 ServerApp]\u001B[m notebook_shim | extension was successfully linked.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.835 ServerApp]\u001B[m notebook_shim | extension was successfully loaded.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.838 ServerApp]\u001B[m jupyter_lsp | extension was successfully loaded.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.839 ServerApp]\u001B[m jupyter_server_terminals | extension was successfully loaded.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.842 LabApp]\u001B[m JupyterLab extension loaded from /Users/maya/PycharmProjects/MachineLearningProject/.venv/lib/python3.10/site-packages/jupyterlab\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.842 LabApp]\u001B[m JupyterLab application directory is /Users/maya/PycharmProjects/MachineLearningProject/.venv/share/jupyter/lab\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.842 LabApp]\u001B[m Extension Manager is 'pypi'.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.846 ServerApp]\u001B[m jupyterlab | extension was successfully loaded.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.850 ServerApp]\u001B[m notebook | extension was successfully loaded.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.851 ServerApp]\u001B[m The port 8888 is already in use, trying another port.\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.851 ServerApp]\u001B[m Serving notebooks from local directory: /Users/maya/PycharmProjects/MachineLearningProject\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.851 ServerApp]\u001B[m Jupyter Server 2.12.5 is running at:\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.851 ServerApp]\u001B[m http://localhost:8889/tree?token=47cf36e02ed82398e8b474872a0ebc633e0bd3b959735c7e\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.852 ServerApp]\u001B[m     http://127.0.0.1:8889/tree?token=47cf36e02ed82398e8b474872a0ebc633e0bd3b959735c7e\r\n",
      "\u001B[32m[I 2024-02-20 16:35:53.852 ServerApp]\u001B[m Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\r\n",
      "\u001B[35m[C 2024-02-20 16:35:53.857 ServerApp]\u001B[m \r\n",
      "    \r\n",
      "    To access the server, open this file in a browser:\r\n",
      "        file:///Users/maya/Library/Jupyter/runtime/jpserver-15933-open.html\r\n",
      "    Or copy and paste one of these URLs:\r\n",
      "        http://localhost:8889/tree?token=47cf36e02ed82398e8b474872a0ebc633e0bd3b959735c7e\r\n",
      "        http://127.0.0.1:8889/tree?token=47cf36e02ed82398e8b474872a0ebc633e0bd3b959735c7e\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f18627649dda2d61"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a6f6a236c63cd31e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:45:38.440304Z",
     "start_time": "2024-02-21T08:45:37.262265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           textID                                               text  \\\n",
      "0      b8f4e560fa   but yeah i like purple maybe thats why!! ;)  ...   \n",
      "1      f81a1511b2  _Henrie haha i WISH i coudl meet you.. you sho...   \n",
      "2      3e9e3f0d69          nah, you`re just altered forever   Enjoy.   \n",
      "3      a068b95bd9   Can you ask Ryan why he stopped following me ...   \n",
      "4      e6da2d1835  New issue of  in the office...desperately want...   \n",
      "...           ...                                                ...   \n",
      "12267  35ee036565  2.5 years here & left Dell OKC for the last ti...   \n",
      "12268  10c23a0f46   That is the best sticker EVER. Also. I dig yo...   \n",
      "12269  a2dd416423  getting dinner ready not much going on in my l...   \n",
      "12270  d9f7bd1045                                 Ow. Sunburn hurts!   \n",
      "12271  33b4f870e8        dont ya know? people love the human society   \n",
      "\n",
      "      sentiment        message_date account_creation_date  \\\n",
      "0      positive   2023-10-2 7:41:52      2015-4-13 0:1:16   \n",
      "1      positive   2022-11-17 2:1:57     2013-7-1 18:58:16   \n",
      "2      positive    2022-6-1 6:53:18      2013-8-8 2:21:12   \n",
      "3      negative   2022-1-4 11:38:57   2015-10-16 14:51:19   \n",
      "4      negative  2022-5-11 21:56:27    2013-12-15 19:8:40   \n",
      "...         ...                 ...                   ...   \n",
      "12267  positive   2022-7-15 7:39:40    2015-12-10 7:35:53   \n",
      "12268  positive   2023-2-11 6:33:29      2013-7-7 9:39:32   \n",
      "12269  negative  2022-10-3 23:37:34       2014-6-3 4:53:4   \n",
      "12270  negative   2023-5-15 20:2:50     2015-3-12 12:18:5   \n",
      "12271  positive     2023-8-3 4:3:33     2013-12-6 18:22:5   \n",
      "\n",
      "                                 previous_messages_dates  \\\n",
      "0      [2019-2-15 16:12:42, 2020-6-2 16:49:53, 2021-4...   \n",
      "1      [2021-7-5 21:53:48, 2020-12-12 9:7:50, 2020-9-...   \n",
      "2      [2021-7-11 9:59:36, 2020-2-18 6:38:45, 2021-5-...   \n",
      "3      [2021-8-16 4:55:32, 2021-6-1 10:13:37, 2021-12...   \n",
      "4      [2021-9-11 10:55:6, 2021-5-6 12:1:54, 2021-1-1...   \n",
      "...                                                  ...   \n",
      "12267  [2020-10-1 16:51:32, 2020-2-2 16:37:3, 2021-11...   \n",
      "12268  [2020-2-14 2:57:10, 2020-7-18 23:19:42, 2019-2...   \n",
      "12269  [2021-8-5 13:31:30, 2020-12-17 11:8:29, 2019-6...   \n",
      "12270  [2021-1-4 21:6:58, 2021-5-7 21:55:4, 2021-4-7 ...   \n",
      "12271  [2019-10-18 10:32:28, 2021-2-4 9:33:15, 2021-2...   \n",
      "\n",
      "                                    date_of_new_follower  \\\n",
      "0      [2016-1-13 7:12:26, 2016-5-17 13:40:38, 2016-1...   \n",
      "1      [2016-10-4 7:49:46, 2016-6-10 7:47:39, 2016-4-...   \n",
      "2      [2018-7-13 17:0:3, 2016-2-13 17:8:12, 2016-2-1...   \n",
      "3                                      [2018-7-1 5:9:39]   \n",
      "4               [2018-11-2 11:16:12, 2018-10-18 16:8:34]   \n",
      "...                                                  ...   \n",
      "12267  [2016-3-18 1:12:13, 2016-2-6 22:13:57, 2016-9-...   \n",
      "12268  [2017-3-2 6:20:34, 2018-6-13 4:14:3, 2016-6-11...   \n",
      "12269  [2016-9-11 15:17:41, 2017-11-10 19:4:6, 2018-6...   \n",
      "12270  [2018-6-12 21:10:51, 2018-2-10 6:29:59, 2018-1...   \n",
      "12271  [2016-7-9 18:39:50, 2016-1-5 23:21:25, 2016-10...   \n",
      "\n",
      "                                      date_of_new_follow  \\\n",
      "0      [2016-7-15 0:3:50, 2016-4-10 22:31:8, 2016-10-...   \n",
      "1      [2016-7-5 20:23:57, 2016-5-3 15:9:51, 2018-11-...   \n",
      "2      [2016-7-9 22:15:10, 2018-4-13 20:37:55, 2016-1...   \n",
      "3      [2018-10-18 7:23:20, 2018-4-10 12:17:6, 2016-6...   \n",
      "4      [2018-4-18 20:56:34, 2018-7-1 14:56:33, 2016-4...   \n",
      "...                                                  ...   \n",
      "12267  [2016-1-8 14:47:24, 2016-11-7 3:1:28, 2016-2-1...   \n",
      "12268  [2016-4-10 21:42:23, 2016-11-10 14:29:50, 2018...   \n",
      "12269  [2018-2-4 9:3:13, 2017-1-3 0:11:2, 2018-12-2 1...   \n",
      "12270                                [2018-8-15 7:36:20]   \n",
      "12271  [2018-3-10 18:1:12, 2016-7-8 14:20:53, 2016-11...   \n",
      "\n",
      "                                    email gender email_verified blue_tick  \\\n",
      "0        ClareRosindill3265@messenger.gov      F            NaN     False   \n",
      "1         ErenaAntonchik231@messenger.gov      M           True      True   \n",
      "2                GodardCowlas6687@api.gov      F           True      True   \n",
      "3           RalfStolberger6467@python.gov      M          False     False   \n",
      "4               MadelLeaton248@bbc.gov.il      M          False     False   \n",
      "...                                   ...    ...            ...       ...   \n",
      "12267         MarlaDyment5684@alibaba.org      F          False       NaN   \n",
      "12268       RaslaGretham960@spotify.ac.il      F           True      True   \n",
      "12269  PackstonTiptaft267@instagram.co.il      F           True     False   \n",
      "12270          AndieChilvers8375@love.com      M          False     False   \n",
      "12271    FernandoKnevet1115@registree.edu   None          False      True   \n",
      "\n",
      "      embedded_content   platform  \n",
      "0                  mp4   facebook  \n",
      "1                False     tiktok  \n",
      "2                False     tiktok  \n",
      "3                  mp4     tiktok  \n",
      "4                 None       None  \n",
      "...                ...        ...  \n",
      "12267            False   facebook  \n",
      "12268            False     tiktok  \n",
      "12269             link   telegram  \n",
      "12270            False  instagram  \n",
      "12271             jpeg   whatsapp  \n",
      "\n",
      "[12272 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.stats import chi2_contingency\n",
    "import re\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "df = pd.read_pickle(r'/Users/maya/Documents/Information Systems/שנה ג׳/למידת מכונה/פרוייקט קורס/XY_train.pkl')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a53fc3597c11509",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:45:44.604119Z",
     "start_time": "2024-02-21T08:45:43.831954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Before and After Deletion:\n",
      "                         Before  After  Difference\n",
      "textID                        0      0           0\n",
      "text                          0      0           0\n",
      "sentiment                     0      0           0\n",
      "message_date                  0      0           0\n",
      "account_creation_date         0      0           0\n",
      "previous_messages_dates       0      0           0\n",
      "date_of_new_follower          0      0           0\n",
      "date_of_new_follow            0      0           0\n",
      "email                       891    825          66\n",
      "gender                     1619   1511         108\n",
      "email_verified             1023    941          82\n",
      "blue_tick                  1439   1354          85\n",
      "embedded_content            906    854          52\n",
      "platform                    750    697          53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m3/b_36s2ds2f304ldssyhqv2sm0000gn/T/ipykernel_965/54234375.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['email_verified'].fillna(df['blue_tick'], inplace=True)\n",
      "/var/folders/m3/b_36s2ds2f304ldssyhqv2sm0000gn/T/ipykernel_965/54234375.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['blue_tick'].fillna(df['email_verified'], inplace=True)\n",
      "/var/folders/m3/b_36s2ds2f304ldssyhqv2sm0000gn/T/ipykernel_965/54234375.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['gender'].replace('None', np.nan, inplace=True)\n",
      "/var/folders/m3/b_36s2ds2f304ldssyhqv2sm0000gn/T/ipykernel_965/54234375.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['gender'].fillna(pd.Series(np.random.choice(gender_counts.index,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#------------PRE-PROCESSING---------------#\n",
    "\n",
    "#--Missing values--\n",
    "# Calculate missing values before deletion\n",
    "missing_values_before = df.isnull().sum()\n",
    "df = df.dropna(thresh=df.shape[1]-2)\n",
    "missing_values_after = df.isnull().sum()\n",
    "missing_values_table = pd.DataFrame({\n",
    "    'Before': missing_values_before,\n",
    "    'After': missing_values_after,\n",
    "    'Difference': missing_values_before - missing_values_after\n",
    "})\n",
    "print(\"Missing Values Before and After Deletion:\")\n",
    "print(missing_values_table)\n",
    "\n",
    "#--filling email iwith the value unknowm--\n",
    "df['email'] = df['email'].fillna('unknown')\n",
    "missing_values_count = df['email'].isnull().sum()\n",
    "\n",
    "#--Filling embedded_content and platform according to their probability--\n",
    "embedded_content_prob = df['embedded_content'].value_counts(normalize=True)\n",
    "platform_prob = df['platform'].value_counts(normalize=True)\n",
    "\n",
    "def impute_missing_values(row, prob_dist):\n",
    "    if pd.isnull(row):\n",
    "        return np.random.choice(prob_dist.index, p=prob_dist.values)\n",
    "    else:\n",
    "        return row\n",
    "df['embedded_content'] = df['embedded_content'].apply(lambda x: impute_missing_values(x, embedded_content_prob))\n",
    "df['platform'] = df['platform'].apply(lambda x: impute_missing_values(x, platform_prob))\n",
    "\n",
    "#--Fill missing values for email_verified and blue_tick--\n",
    "df['email_verified'].fillna(df['blue_tick'], inplace=True)\n",
    "df['blue_tick'].fillna(df['email_verified'], inplace=True)\n",
    "\n",
    "#--filling gender randomly--\n",
    "df['gender'].replace('None', np.nan, inplace=True)\n",
    "gender_counts = df['gender'].value_counts()\n",
    "df['gender'].fillna(pd.Series(np.random.choice(gender_counts.index,\n",
    "                                               size=len(df.index),\n",
    "                                               p=(gender_counts / gender_counts.sum()))),\n",
    "                    inplace=True)\n",
    "\n",
    "#--Droping the rows with missing values--\n",
    "df = df.dropna()\n",
    "\n",
    "#Converting message_date to categorical\n",
    "df['message_date'] = pd.to_datetime(df['message_date'])\n",
    "df['hour'] = df['message_date'].dt.hour\n",
    "morning_interval = range(6, 12)  # 6:00 AM to 11:59 AM\n",
    "noon_interval = range(12, 18)     # 12:00 PM to 5:59 PM\n",
    "evening_interval = range(18, 24)  # 6:00 PM to 11:59 PM\n",
    "def categorize_hour(hour):\n",
    "    if hour in morning_interval:\n",
    "        return 'Morning'\n",
    "    elif hour in noon_interval:\n",
    "        return 'Noon'\n",
    "    elif hour in evening_interval:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "df['message_time_category'] = df['hour'].apply(categorize_hour)\n",
    "df.drop(columns=['hour'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f4c0e23a79e5e313",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:45:57.787233Z",
     "start_time": "2024-02-21T08:45:51.932962Z"
    }
   },
   "outputs": [],
   "source": [
    "#Changes in Data For n-gram#\n",
    "\n",
    "#Lower case\n",
    "lower = df['text'].apply(str.lower)\n",
    "\n",
    "\n",
    "#Stemming\n",
    "from nltk.stem import SnowballStemmer\n",
    "stem = SnowballStemmer('english')\n",
    "stemmed = lower.apply(lambda x: ' '.join(stem.stem(word) for word in str(x).split()))\n",
    "    \n",
    "\n",
    "#removing punctuation\n",
    "import re\n",
    "rem_punc = stemmed.apply(lambda x: re.sub(r'[^\\w\\s]',' ',x))\n",
    "\n",
    "\n",
    "#removing numbers\n",
    "rem_num = rem_punc.apply(lambda x: \" \".join(x for x in x.split() if not x.isdigit()))\n",
    "\n",
    "#removing words with 1 letter\n",
    "rem_length1 = rem_num.apply(lambda x: re.sub(r'\\b\\w{1}\\b',' ',x))\n",
    "\n",
    "# Remove top 0.05% of most common or not common words\n",
    "h_pct = 0.05\n",
    "l_pct = 0.05\n",
    "\n",
    "#removing the top $h_pct of the most frequent words \n",
    "high_freq = pd.Series(''.join(rem_length1).split()).value_counts()[:int(pd.Series(' '.join(rem_length1).split()).count()*h_pct/100)]\n",
    "\n",
    "rem_high = rem_length1.apply(lambda x: \" \".join(x for x in x.split() if x not in high_freq))\n",
    "    \n",
    "#removing the top $l_pct of the least frequent words\n",
    "low_freq = pd.Series(''.join(rem_high).split()).value_counts()[:-int(pd.Series(' '.join(rem_high).split()).count()*l_pct/100):-1]\n",
    "\n",
    "rem_low = rem_high.apply(lambda x: \" \".join(x for x in x.split() if x not in low_freq))\n",
    "\n",
    "# Remove double spaces\n",
    "rem_punc = rem_low.apply(lambda x: re.sub(r'[^\\w\\s]',' ',x))\n",
    "\n",
    "df['clean_text'] = rem_punc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b055fc04c407971",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:46:17.394477Z",
     "start_time": "2024-02-21T08:46:01.048830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized message_length:\n",
      "0        0.361702\n",
      "1        0.843972\n",
      "2        0.297872\n",
      "3        0.397163\n",
      "4        0.751773\n",
      "           ...   \n",
      "12266    0.595745\n",
      "12267    0.950355\n",
      "12268    0.687943\n",
      "12269    0.411348\n",
      "12270    0.127660\n",
      "Name: normalized_message_length, Length: 12026, dtype: float64\n",
      "Normalized num_messages_sent:\n",
      "0        0.244898\n",
      "1        0.979592\n",
      "2        0.612245\n",
      "3        0.102041\n",
      "4        0.163265\n",
      "           ...   \n",
      "12266    0.714286\n",
      "12267    0.448980\n",
      "12268    0.469388\n",
      "12269    0.061224\n",
      "12270    0.142857\n",
      "Name: normalized_num_messages_sent, Length: 12026, dtype: float64\n",
      "Normalized follower_count:\n",
      "0        0.897959\n",
      "1        0.367347\n",
      "2        0.306122\n",
      "3        0.020408\n",
      "4        0.040816\n",
      "           ...   \n",
      "12266    0.469388\n",
      "12267    0.489796\n",
      "12268    0.775510\n",
      "12269    0.122449\n",
      "12270    0.163265\n",
      "Name: normalized_follower_count, Length: 12026, dtype: float64\n",
      "Normalized following_count:\n",
      "0        0.285714\n",
      "1        0.857143\n",
      "2        0.489796\n",
      "3        0.081633\n",
      "4        0.122449\n",
      "           ...   \n",
      "12266    0.653061\n",
      "12267    0.244898\n",
      "12268    0.306122\n",
      "12269    0.102041\n",
      "12270    0.020408\n",
      "Name: normalized_following_count, Length: 12026, dtype: float64\n",
      "Normalized seniority:\n",
      "0        0.795477\n",
      "1        0.955261\n",
      "2        0.946165\n",
      "3        0.749508\n",
      "4        0.914208\n",
      "           ...   \n",
      "12266    0.946657\n",
      "12267    0.736234\n",
      "12268    0.954031\n",
      "12269    0.872665\n",
      "12270    0.803097\n",
      "Name: normalized_seniority, Length: 12026, dtype: float64\n",
      "Normalized average_time_difference:\n",
      "0        0.319333\n",
      "1        0.316612\n",
      "2        0.342311\n",
      "3        0.111148\n",
      "4        0.161843\n",
      "           ...   \n",
      "12266    0.220350\n",
      "12267    0.379692\n",
      "12268    0.332362\n",
      "12269    0.372905\n",
      "12270    0.101888\n",
      "Name: normalized_average_time_difference, Length: 12026, dtype: float64\n",
      "Normalized follower_following_diff:\n",
      "0        0.612245\n",
      "1        0.489796\n",
      "2        0.183673\n",
      "3        0.061224\n",
      "4        0.081633\n",
      "           ...   \n",
      "12266    0.183673\n",
      "12267    0.244898\n",
      "12268    0.469388\n",
      "12269    0.020408\n",
      "12270    0.142857\n",
      "Name: normalized_follower_following_diff, Length: 12026, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": "       textID  sentiment  gender  email_verified  blue_tick  \\\n0  b8f4e560fa          1       1               0          0   \n1  f81a1511b2          1       0               1          1   \n2  3e9e3f0d69          1       1               1          1   \n3  a068b95bd9         -1       0               0          0   \n4  e6da2d1835         -1       0               0          0   \n\n   normalized_message_length  normalized_num_messages_sent  \\\n0                   0.361702                      0.244898   \n1                   0.843972                      0.979592   \n2                   0.297872                      0.612245   \n3                   0.397163                      0.102041   \n4                   0.751773                      0.163265   \n\n   normalized_follower_count  normalized_following_count  \\\n0                   0.897959                    0.285714   \n1                   0.367347                    0.857143   \n2                   0.306122                    0.489796   \n3                   0.020408                    0.081633   \n4                   0.040816                    0.122449   \n\n   normalized_seniority  ...  week  weekend  well  were  when       whi  who  \\\n0              0.795477  ...   0.0      0.0   0.0   0.0   0.0  0.000000  0.0   \n1              0.955261  ...   0.0      0.0   0.0   0.0   0.0  0.000000  0.0   \n2              0.946165  ...   0.0      0.0   0.0   0.0   0.0  0.000000  0.0   \n3              0.749508  ...   0.0      0.0   0.0   0.0   0.0  0.333333  0.0   \n4              0.914208  ...   0.0      0.0   0.0   0.0   0.0  0.000000  0.0   \n\n   wish  would  yeah  \n0   0.0    0.0   0.5  \n1   1.0    0.0   0.0  \n2   0.0    0.0   0.0  \n3   0.0    0.0   0.0  \n4   0.0    0.0   0.0  \n\n[5 rows x 136 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>sentiment</th>\n      <th>gender</th>\n      <th>email_verified</th>\n      <th>blue_tick</th>\n      <th>normalized_message_length</th>\n      <th>normalized_num_messages_sent</th>\n      <th>normalized_follower_count</th>\n      <th>normalized_following_count</th>\n      <th>normalized_seniority</th>\n      <th>...</th>\n      <th>week</th>\n      <th>weekend</th>\n      <th>well</th>\n      <th>were</th>\n      <th>when</th>\n      <th>whi</th>\n      <th>who</th>\n      <th>wish</th>\n      <th>would</th>\n      <th>yeah</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b8f4e560fa</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.361702</td>\n      <td>0.244898</td>\n      <td>0.897959</td>\n      <td>0.285714</td>\n      <td>0.795477</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f81a1511b2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.843972</td>\n      <td>0.979592</td>\n      <td>0.367347</td>\n      <td>0.857143</td>\n      <td>0.955261</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3e9e3f0d69</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.297872</td>\n      <td>0.612245</td>\n      <td>0.306122</td>\n      <td>0.489796</td>\n      <td>0.946165</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a068b95bd9</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.397163</td>\n      <td>0.102041</td>\n      <td>0.020408</td>\n      <td>0.081633</td>\n      <td>0.749508</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e6da2d1835</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.751773</td>\n      <td>0.163265</td>\n      <td>0.040816</td>\n      <td>0.122449</td>\n      <td>0.914208</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 136 columns</p>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#1.Create a new column based on the length of messages\n",
    "df['message_length'] = df['text'].apply(lambda x: len(x))\n",
    "#2.Creating the number of messages sent by the user\n",
    "df['num_messages_sent'] = df['previous_messages_dates'].apply(len)\n",
    "#3.creating num of followers and following\n",
    "df['follower_count'] = df['date_of_new_follower'].apply(lambda x: len(x))\n",
    "df['following_count'] = df['date_of_new_follow'].apply(lambda x: len(x))\n",
    "\n",
    "#4.creating the difference between followers and following\n",
    "df['follower_following_diff'] = abs(df['following_count'] - df['follower_count'])\n",
    "new_columns_df = df[['follower_count', 'following_count', 'follower_following_diff']]\n",
    "\n",
    "# #5.N-GRAM\n",
    "\n",
    "#------- tamar ngram ---------#\n",
    "# ngram_range = (2, 2)  # Set N-gram range to bi-grams\n",
    "# vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=20)\n",
    "# X_text_features = vectorizer.fit_transform(df['text'])\n",
    "# df = pd.concat([df.reset_index(drop=True), pd.DataFrame(X_text_features.toarray())], axis=1)\n",
    "#------- tamar ngram ---------#\n",
    "\n",
    "X = df['clean_text']\n",
    "Y = df['sentiment']\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2), max_features = 100)\n",
    "X_ngrams = ngram_vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "# Check words frequency\n",
    "# sum_of_words = X_ngrams.sum(axis = 0)\n",
    "# words_freq = [(word, sum_of_words[i]) for word, i in ngram_vectorizer.vocabulary_.items()]\n",
    "# words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "# \n",
    "# print(words_freq)\n",
    "\n",
    "df_output = pd.DataFrame(data = X_ngrams, columns = ngram_vectorizer.get_feature_names_out())\n",
    "# df = pd.concat([df.reset_index(drop=True), pd.DataFrame(df_output)], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#6.Extracting email domain endings\n",
    "def extract_email_domain_ending(email):\n",
    "    if pd.isnull(email):\n",
    "        return 'Missing'\n",
    "    match = re.search(r'\\.(\\w+)$', email)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "df['email_domain_ending'] = df['email'].apply(extract_email_domain_ending)\n",
    "email_domain_ending_counts = df['email_domain_ending'].value_counts()\n",
    "\n",
    "#7.Creating seniority in years\n",
    "df['account_creation_date'] = pd.to_datetime(df['account_creation_date'])\n",
    "current_date = datetime.now()\n",
    "df['seniority'] = (current_date - df['account_creation_date']).dt.days / 365.25\n",
    "\n",
    "#8.Creating the average time difference between messages\n",
    "def calculate_average_time_difference(message_dates_array):\n",
    "    message_dates = [datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S') for date_str in message_dates_array]\n",
    "    time_diffs = []\n",
    "    for i in range(1, len(message_dates)):\n",
    "        time_diff = (message_dates[i] - message_dates[i - 1]).total_seconds()\n",
    "        if time_diff < 0:\n",
    "            time_diff = (message_dates[i - 1] - message_dates[i]).total_seconds()\n",
    "        time_diffs.append(time_diff)\n",
    "    if len(time_diffs) > 0:\n",
    "        average_time_difference = sum(time_diffs) / len(time_diffs)\n",
    "        average_time_difference = int(average_time_difference)\n",
    "        return average_time_difference\n",
    "    else:\n",
    "        return None\n",
    "df['average_time_difference'] = df['previous_messages_dates'].apply(calculate_average_time_difference)\n",
    "\n",
    "#4.Feature representation--------------------------------------------------->\n",
    "\n",
    "#1.Normalized values by dividing each column by its maximum value\n",
    "columns_to_normalize = ['message_length', 'num_messages_sent', 'follower_count', 'following_count',\n",
    "                        'seniority', 'average_time_difference', 'follower_following_diff']\n",
    "for column in columns_to_normalize:\n",
    "    max_value = df[column].max()\n",
    "    df[f'normalized_{column}'] = df[column] / max_value\n",
    "for column in columns_to_normalize:\n",
    "    normalized_column_name = f'normalized_{column}'\n",
    "    print(f\"Normalized {column}:\")\n",
    "    print(df[normalized_column_name])\n",
    "\n",
    "#2.One-hot encoding\n",
    "email_domain_ending_onehot = pd.get_dummies(df['email_domain_ending'], prefix='email_ending')\n",
    "embedded_content_onehot = pd.get_dummies(df['embedded_content'], prefix='embedded_content')\n",
    "platform_onehot = pd.get_dummies(df['platform'], prefix='platform')\n",
    "message_time_category_onehot = pd.get_dummies(df['message_time_category'], prefix='message_time')\n",
    "df = pd.concat([df, email_domain_ending_onehot, embedded_content_onehot, platform_onehot, message_time_category_onehot], axis=1)\n",
    "df.drop(['email_domain_ending', 'embedded_content', 'platform', 'message_time_category'], axis=1, inplace=True)\n",
    "\n",
    "#3.Converting to binary values\n",
    "bool_to_binary = {True: 1, False: 0}\n",
    "df['email_verified'] = df['email_verified'].map(bool_to_binary)\n",
    "df['blue_tick'] = df['blue_tick'].map(bool_to_binary)\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == bool:\n",
    "        df[column] = df[column].astype(int) \n",
    "\n",
    "gender_to_binary = {'F': 1, 'M': 0}\n",
    "df['gender'] = df['gender'].map(gender_to_binary)\n",
    "\n",
    "#4. Normalization the n-gram features\n",
    "scaler = MinMaxScaler()\n",
    "X_ngrams_normalized = scaler.fit_transform(X_ngrams)\n",
    "df_normalized = pd.DataFrame(X_ngrams_normalized, columns=ngram_vectorizer.get_feature_names_out())\n",
    "df = pd.concat([df.reset_index(drop=True), df_normalized], axis=1)\n",
    "\n",
    "\n",
    "#6.Data arrangement\n",
    "sentiment_mapping = {'positive': 1, 'negative': -1}\n",
    "df['sentiment'] = df['sentiment'].map(sentiment_mapping)\n",
    "df = df.drop(columns=['text', 'previous_messages_dates', 'message_date',\n",
    "                      'email', 'date_of_new_follower', 'date_of_new_follow',\n",
    "                      'account_creation_date', 'message_length', 'num_messages_sent',\n",
    "                      'follower_count', 'following_count', 'follower_following_diff',\n",
    "                      'seniority', 'average_time_difference', 'clean_text'])\n",
    "\n",
    "\n",
    "#5.Feature selection-------------------------------------------------------->\n",
    "\n",
    "df.head()\n",
    "\n",
    "#6.dimensionality reduction------------------------------------------------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc098bc7c46df7b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T14:24:20.225580Z",
     "start_time": "2024-02-20T14:24:18.790560Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fisher Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normalized_num_messages_sent</th>\n",
       "      <td>2.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_follower_count</th>\n",
       "      <td>1.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_following_count</th>\n",
       "      <td>1.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_follower_following_diff</th>\n",
       "      <td>1.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_verified</th>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue_tick</th>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform_instagram</th>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_seniority</th>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedded_content_False</th>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_time_Evening</th>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedded_content_mp4</th>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sad</th>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform_telegram</th>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedded_content_link</th>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sorri</th>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_ending_edu</th>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_time_Morning</th>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sick</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enjoy</th>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_time_Night</th>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurt</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesom</th>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_ending_ke</th>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cool</th>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morn</th>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom</th>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform_facebook</th>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haha</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform_tiktok</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whi</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>better</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_ending_il</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_ending_de</th>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embedded_content_jpeg</th>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_time_Noon</th>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lol</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform_x</th>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cant</th>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wish</th>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>down</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didn</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>when</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gonna</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>though</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitpic</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>been</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomorrow</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tri</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>then</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>were</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekend</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onli</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peopl</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watch</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veri</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleep</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>show</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>how</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_ending_jp</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_ending_gov</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_ending_com</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>again</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tonight</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>after</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform_whatsapp</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_ending_ru</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bit</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_ending_org</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>email_ending_Unknown</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_average_time_difference</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_message_length</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>there</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>than</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>them</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>if</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>here</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>should</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friend</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>did</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>take</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeah</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Fisher Score\n",
       "normalized_num_messages_sent               2.077\n",
       "normalized_follower_count                  1.861\n",
       "normalized_following_count                 1.762\n",
       "normalized_follower_following_diff         1.258\n",
       "email_verified                             0.202\n",
       "blue_tick                                  0.169\n",
       "gender                                     0.150\n",
       "platform_instagram                         0.129\n",
       "normalized_seniority                       0.104\n",
       "thank                                      0.075\n",
       "embedded_content_False                     0.062\n",
       "message_time_Evening                       0.056\n",
       "embedded_content_mp4                       0.054\n",
       "sad                                        0.052\n",
       "platform_telegram                          0.039\n",
       "hate                                       0.032\n",
       "embedded_content_link                      0.032\n",
       "nice                                       0.031\n",
       "sorri                                      0.029\n",
       "email_ending_edu                           0.028\n",
       "bad                                        0.026\n",
       "message_time_Morning                       0.024\n",
       "sick                                       0.020\n",
       "fun                                        0.020\n",
       "enjoy                                      0.018\n",
       "message_time_Night                         0.018\n",
       "hurt                                       0.016\n",
       "awesom                                     0.015\n",
       "best                                       0.014\n",
       "email_ending_ke                            0.014\n",
       "cool                                       0.014\n",
       "morn                                       0.010\n",
       "mom                                        0.010\n",
       "platform_facebook                          0.010\n",
       "haha                                       0.009\n",
       "platform_tiktok                            0.009\n",
       "whi                                        0.009\n",
       "better                                     0.009\n",
       "email_ending_il                            0.009\n",
       "email_ending_de                            0.008\n",
       "embedded_content_jpeg                      0.007\n",
       "message_time_Noon                          0.007\n",
       "lol                                        0.006\n",
       "platform_x                                 0.006\n",
       "cant                                       0.005\n",
       "wish                                       0.005\n",
       "new                                        0.004\n",
       "dont                                       0.004\n",
       "down                                       0.004\n",
       "still                                      0.003\n",
       "didn                                       0.003\n",
       "has                                        0.003\n",
       "need                                       0.003\n",
       "final                                      0.003\n",
       "follow                                     0.003\n",
       "would                                      0.002\n",
       "or                                         0.002\n",
       "over                                       0.002\n",
       "when                                       0.002\n",
       "gonna                                      0.002\n",
       "though                                     0.002\n",
       "twitpic                                    0.002\n",
       "been                                       0.002\n",
       "tomorrow                                   0.001\n",
       "tri                                        0.001\n",
       "then                                       0.001\n",
       "were                                       0.001\n",
       "weekend                                    0.001\n",
       "onli                                       0.001\n",
       "sure                                       0.001\n",
       "school                                     0.001\n",
       "peopl                                      0.001\n",
       "right                                      0.001\n",
       "watch                                      0.001\n",
       "well                                       0.001\n",
       "veri                                       0.001\n",
       "wait                                       0.001\n",
       "sleep                                      0.001\n",
       "show                                       0.001\n",
       "he                                         0.001\n",
       "man                                        0.001\n",
       "how                                        0.001\n",
       "ever                                       0.001\n",
       "even                                       0.001\n",
       "email_ending_jp                            0.001\n",
       "email_ending_gov                           0.001\n",
       "email_ending_com                           0.001\n",
       "ll                                         0.001\n",
       "long                                       0.001\n",
       "again                                      0.001\n",
       "tonight                                    0.000\n",
       "twitter                                    0.000\n",
       "as                                         0.000\n",
       "bed                                        0.000\n",
       "thing                                      0.000\n",
       "an                                         0.000\n",
       "tweet                                      0.000\n",
       "way                                        0.000\n",
       "after                                      0.000\n",
       "platform_whatsapp                          0.000\n",
       "email_ending_ru                            0.000\n",
       "bit                                        0.000\n",
       "week                                       0.000\n",
       "email_ending_org                           0.000\n",
       "email_ending_Unknown                       0.000\n",
       "who                                        0.000\n",
       "normalized_average_time_difference         0.000\n",
       "normalized_message_length                  0.000\n",
       "there                                      0.000\n",
       "than                                       0.000\n",
       "them                                       0.000\n",
       "by                                         0.000\n",
       "last                                       0.000\n",
       "next                                       0.000\n",
       "if                                         0.000\n",
       "off                                        0.000\n",
       "oh                                         0.000\n",
       "home                                       0.000\n",
       "him                                        0.000\n",
       "here                                       0.000\n",
       "her                                        0.000\n",
       "guy                                        0.000\n",
       "say                                        0.000\n",
       "girl                                       0.000\n",
       "she                                        0.000\n",
       "should                                     0.000\n",
       "friend                                     0.000\n",
       "did                                        0.000\n",
       "start                                      0.000\n",
       "could                                      0.000\n",
       "come                                       0.000\n",
       "take                                       0.000\n",
       "more                                       0.000\n",
       "yeah                                       0.000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Separate the dataset into positive and negative sentiment groups\n",
    "# positive_sentiment = df[df['sentiment'] == 1]\n",
    "# negative_sentiment = df[df['sentiment'] == -1]\n",
    "# \n",
    "# # Remove 'sentiment', 'textID' columns as we are not considering it as a feature\n",
    "# features = df.drop(columns=['sentiment', 'textID']).columns\n",
    "# \n",
    "# # print(features)\n",
    "# \n",
    "# fisher_scores = {}\n",
    "# \n",
    "# # Calculate Fisher score for each feature\n",
    "# for feature in features:\n",
    "#     mean_positive = positive_sentiment[feature].mean()\n",
    "#     mean_negative = negative_sentiment[feature].mean()\n",
    "#     var_positive = positive_sentiment[feature].var()\n",
    "#     var_negative = negative_sentiment[feature].var()\n",
    "#     \n",
    "#     # print(var_negative)\n",
    "#     # print(var_positive)\n",
    "#     \n",
    "#     fisher_score = ((mean_positive - mean_negative)**2) / (var_positive + var_negative)\n",
    "#     # print(feature)\n",
    "#     fisher_scores[feature] = round(fisher_score, 3)  # Round to 3 decimal places\n",
    "#     \n",
    "# # print(fisher_scores)\n",
    "# \n",
    "# # Create DataFrame from dictionary\n",
    "# fisher_df = pd.DataFrame.from_dict(fisher_scores, orient='index', columns=['Fisher Score'])\n",
    "# \n",
    "# # Sort features based on their Fisher scores\n",
    "# fisher_df = fisher_df.sort_values(by='Fisher Score', ascending=False)\n",
    "# \n",
    "# # Set options to display all rows and columns\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# \n",
    "# # Print the DataFrame\n",
    "# fisher_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6c363b-f8cb-402d-96d1-8bb0447c6d6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T08:54:25.415480Z",
     "start_time": "2024-02-21T08:54:23.140609Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 8\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Assuming 'X_cat' is your feature matrix and 'Y' is your target variable\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# df = df.drop(columns=['normalized_average_time_difference', 'normalized_follower_following_diff'])\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Extract the target variable 'sentiment'\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m Y \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Drop the 'textID' column from the feature DataFrame\u001B[39;00m\n\u001B[1;32m     11\u001B[0m X_cat \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtextID\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'X_cat' is your feature matrix and 'Y' is your target variable\n",
    "# df = df.drop(columns=['normalized_average_time_difference', 'normalized_follower_following_diff'])\n",
    "\n",
    "# Extract the target variable 'sentiment'\n",
    "Y = df['sentiment']\n",
    "\n",
    "# Drop the 'textID' column from the feature DataFrame\n",
    "X_cat = df.drop(columns=['textID', 'sentiment'])\n",
    "\n",
    "# Initialize SelectKBest with chi-squared as the scoring function and k=15\n",
    "chi2_features = SelectKBest(chi2, k=15)\n",
    "\n",
    "# Fit SelectKBest to the data and transform it\n",
    "X_cat_kbest = chi2_features.fit_transform(X_cat, Y)\n",
    "\n",
    "# Get the p-values of the features and round to 4 digits\n",
    "p_values = chi2_features.pvalues_\n",
    "p_values_rounded = np.round(p_values, 6)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_cat.columns[chi2_features.get_support()]\n",
    "\n",
    "# Convert the array of rounded p-values into a DataFrame\n",
    "p_values_df = pd.DataFrame({'Feature': X_cat.columns, 'P-value': p_values_rounded})\n",
    "\n",
    "# Filter the selected features based on the support\n",
    "selected_features_df = pd.DataFrame({'Feature': selected_features})\n",
    "\n",
    "# Print the DataFrames\n",
    "print(\"P-values DataFrame:\")\n",
    "print(p_values_df)\n",
    "\n",
    "print(\"\\nSelected Features DataFrame:\")\n",
    "selected_features_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                         Feature  P-value\n0                         gender      0.0\n1                 email_verified      0.0\n2                      blue_tick      0.0\n3   normalized_num_messages_sent      0.0\n4      normalized_follower_count      0.0\n5     normalized_following_count      0.0\n6               email_ending_edu      0.0\n7         embedded_content_False      0.0\n8          embedded_content_link      0.0\n9           embedded_content_mp4      0.0\n10            platform_instagram      0.0\n11             platform_telegram      0.0\n12          message_time_Evening      0.0\n13                           sad      0.0\n14                         thank      0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>P-value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gender</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>email_verified</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>blue_tick</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>normalized_num_messages_sent</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>normalized_follower_count</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>normalized_following_count</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>email_ending_edu</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>embedded_content_False</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>embedded_content_link</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>embedded_content_mp4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>platform_instagram</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>platform_telegram</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>message_time_Evening</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>sad</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>thank</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values_df_sorted = p_values_df.sort_values(by='P-value')\n",
    "selected_features_with_p_values = pd.merge(selected_features_df, p_values_df_sorted, on='Feature')\n",
    "\n",
    "selected_features_with_p_values\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:52:15.319023Z",
     "start_time": "2024-02-21T08:52:15.254449Z"
    }
   },
   "id": "f903ad2e29b0d03f",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7ce85b9-2cda-4466-a477-382c7be0e5d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T16:08:15.017232Z",
     "start_time": "2024-02-20T16:08:14.993710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           textID  sentiment  gender  email_verified  blue_tick  \\\n0      b8f4e560fa          1     1.0             0.0        0.0   \n1      f81a1511b2          1     0.0             1.0        1.0   \n2      3e9e3f0d69          1     1.0             1.0        1.0   \n3      a068b95bd9         -1     0.0             0.0        0.0   \n4      e6da2d1835         -1     0.0             0.0        0.0   \n...           ...        ...     ...             ...        ...   \n12021  d44a6cf5cd          1     1.0             1.0        1.0   \n12022  35ee036565          1     1.0             0.0        0.0   \n12023  10c23a0f46          1     1.0             1.0        1.0   \n12024  a2dd416423         -1     1.0             1.0        0.0   \n12025  d9f7bd1045         -1     0.0             0.0        0.0   \n\n       normalized_num_messages_sent  normalized_follower_count  \\\n0                          0.244898                   0.897959   \n1                          0.979592                   0.367347   \n2                          0.612245                   0.306122   \n3                          0.102041                   0.020408   \n4                          0.163265                   0.040816   \n...                             ...                        ...   \n12021                      0.714286                   0.469388   \n12022                      0.448980                   0.489796   \n12023                      0.469388                   0.775510   \n12024                      0.061224                   0.122449   \n12025                      0.142857                   0.163265   \n\n       normalized_following_count  normalized_follower_following_diff  \\\n0                        0.285714                            0.612245   \n1                        0.857143                            0.489796   \n2                        0.489796                            0.183673   \n3                        0.081633                            0.061224   \n4                        0.122449                            0.081633   \n...                           ...                                 ...   \n12021                    0.653061                            0.183673   \n12022                    0.244898                            0.244898   \n12023                    0.306122                            0.469388   \n12024                    0.102041                            0.020408   \n12025                    0.020408                            0.142857   \n\n       embedded_content_mp4  platform_instagram  message_time_Evening  \n0                       1.0                 0.0                   0.0  \n1                       0.0                 0.0                   0.0  \n2                       0.0                 0.0                   0.0  \n3                       1.0                 0.0                   0.0  \n4                       1.0                 0.0                   1.0  \n...                     ...                 ...                   ...  \n12021                   0.0                 1.0                   0.0  \n12022                   0.0                 0.0                   0.0  \n12023                   0.0                 0.0                   0.0  \n12024                   0.0                 0.0                   1.0  \n12025                   0.0                 1.0                   1.0  \n\n[12026 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>sentiment</th>\n      <th>gender</th>\n      <th>email_verified</th>\n      <th>blue_tick</th>\n      <th>normalized_num_messages_sent</th>\n      <th>normalized_follower_count</th>\n      <th>normalized_following_count</th>\n      <th>normalized_follower_following_diff</th>\n      <th>embedded_content_mp4</th>\n      <th>platform_instagram</th>\n      <th>message_time_Evening</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b8f4e560fa</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.244898</td>\n      <td>0.897959</td>\n      <td>0.285714</td>\n      <td>0.612245</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f81a1511b2</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.979592</td>\n      <td>0.367347</td>\n      <td>0.857143</td>\n      <td>0.489796</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3e9e3f0d69</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.612245</td>\n      <td>0.306122</td>\n      <td>0.489796</td>\n      <td>0.183673</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a068b95bd9</td>\n      <td>-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.102041</td>\n      <td>0.020408</td>\n      <td>0.081633</td>\n      <td>0.061224</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>e6da2d1835</td>\n      <td>-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.163265</td>\n      <td>0.040816</td>\n      <td>0.122449</td>\n      <td>0.081633</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12021</th>\n      <td>d44a6cf5cd</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.714286</td>\n      <td>0.469388</td>\n      <td>0.653061</td>\n      <td>0.183673</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12022</th>\n      <td>35ee036565</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.448980</td>\n      <td>0.489796</td>\n      <td>0.244898</td>\n      <td>0.244898</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12023</th>\n      <td>10c23a0f46</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.469388</td>\n      <td>0.775510</td>\n      <td>0.306122</td>\n      <td>0.469388</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12024</th>\n      <td>a2dd416423</td>\n      <td>-1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.061224</td>\n      <td>0.122449</td>\n      <td>0.102041</td>\n      <td>0.020408</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>12025</th>\n      <td>d9f7bd1045</td>\n      <td>-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.142857</td>\n      <td>0.163265</td>\n      <td>0.020408</td>\n      <td>0.142857</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>12026 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the selected features\n",
    "selected_df = pd.DataFrame(X_cat_kbest, columns=selected_features)\n",
    "\n",
    "# Add 'sentiment' and 'textID' columns to the DataFrame\n",
    "selected_df['sentiment'] = df['sentiment']\n",
    "selected_df['textID'] = df['textID']\n",
    "\n",
    "# Reorder the columns to have 'sentiment' and 'textID' as the first columns\n",
    "selected_df = selected_df[['textID', 'sentiment'] + selected_features.tolist()]\n",
    "\n",
    "# Print the DataFrame\n",
    "selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "286e6646fa225fa4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T08:22:05.188037Z",
     "start_time": "2024-02-21T08:21:59.361311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking:\n",
      "gender: 10\n",
      "email_verified: 5\n",
      "blue_tick: 18\n",
      "normalized_message_length: 72\n",
      "normalized_num_messages_sent: 1\n",
      "normalized_follower_count: 1\n",
      "normalized_following_count: 1\n",
      "normalized_seniority: 1\n",
      "email_ending_Unknown: 97\n",
      "email_ending_com: 102\n",
      "email_ending_de: 34\n",
      "email_ending_edu: 27\n",
      "email_ending_gov: 90\n",
      "email_ending_il: 87\n",
      "email_ending_jp: 108\n",
      "email_ending_ke: 62\n",
      "email_ending_org: 88\n",
      "email_ending_ru: 89\n",
      "embedded_content_False: 19\n",
      "embedded_content_jpeg: 20\n",
      "embedded_content_link: 98\n",
      "embedded_content_mp4: 84\n",
      "platform_facebook: 110\n",
      "platform_instagram: 8\n",
      "platform_telegram: 47\n",
      "platform_tiktok: 96\n",
      "platform_whatsapp: 79\n",
      "platform_x: 31\n",
      "message_time_Evening: 13\n",
      "message_time_Morning: 116\n",
      "message_time_Night: 111\n",
      "message_time_Noon: 60\n",
      "after: 93\n",
      "again: 12\n",
      "an: 28\n",
      "as: 106\n",
      "awesom: 1\n",
      "bad: 1\n",
      "bed: 114\n",
      "been: 50\n",
      "best: 1\n",
      "better: 3\n",
      "bit: 63\n",
      "by: 15\n",
      "cant: 24\n",
      "come: 115\n",
      "cool: 2\n",
      "could: 57\n",
      "did: 91\n",
      "didn: 26\n",
      "dont: 101\n",
      "down: 4\n",
      "enjoy: 1\n",
      "even: 49\n",
      "ever: 37\n",
      "final: 6\n",
      "follow: 94\n",
      "friend: 32\n",
      "fun: 1\n",
      "girl: 66\n",
      "gonna: 22\n",
      "guy: 17\n",
      "haha: 1\n",
      "has: 61\n",
      "hate: 1\n",
      "he: 68\n",
      "her: 59\n",
      "here: 107\n",
      "him: 52\n",
      "home: 46\n",
      "how: 25\n",
      "hurt: 14\n",
      "if: 43\n",
      "last: 45\n",
      "ll: 55\n",
      "lol: 74\n",
      "long: 109\n",
      "man: 70\n",
      "mom: 44\n",
      "more: 64\n",
      "morn: 7\n",
      "need: 35\n",
      "new: 67\n",
      "next: 113\n",
      "nice: 1\n",
      "off: 118\n",
      "oh: 29\n",
      "onli: 69\n",
      "or: 56\n",
      "over: 21\n",
      "peopl: 23\n",
      "right: 86\n",
      "sad: 1\n",
      "say: 77\n",
      "school: 42\n",
      "she: 30\n",
      "should: 112\n",
      "show: 38\n",
      "sick: 11\n",
      "sleep: 73\n",
      "sorri: 1\n",
      "start: 76\n",
      "still: 39\n",
      "sure: 51\n",
      "take: 81\n",
      "than: 99\n",
      "thank: 1\n",
      "them: 9\n",
      "then: 16\n",
      "there: 85\n",
      "thing: 103\n",
      "though: 36\n",
      "tomorrow: 105\n",
      "tonight: 80\n",
      "tri: 104\n",
      "tweet: 48\n",
      "twitpic: 82\n",
      "twitter: 92\n",
      "veri: 117\n",
      "wait: 33\n",
      "watch: 100\n",
      "way: 41\n",
      "week: 71\n",
      "weekend: 53\n",
      "well: 83\n",
      "were: 65\n",
      "when: 54\n",
      "whi: 40\n",
      "who: 95\n",
      "wish: 58\n",
      "would: 78\n",
      "yeah: 75\n",
      "\n",
      "Selected Features:\n",
      "Index(['normalized_num_messages_sent', 'normalized_follower_count',\n",
      "       'normalized_following_count', 'normalized_seniority', 'awesom', 'bad',\n",
      "       'best', 'enjoy', 'fun', 'haha', 'hate', 'nice', 'sad', 'sorri',\n",
      "       'thank'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming 'X_cat' is your feature matrix and 'Y' is your target variable\n",
    "# df = df.drop(columns=['normalized_average_time_difference', 'normalized_follower_following_diff'])\n",
    "\n",
    "# Extract the target variable 'sentiment'\n",
    "Y = df['sentiment']\n",
    "\n",
    "# Drop the 'textID' column from the feature DataFrame\n",
    "X_cat = df.drop(columns=['textID', 'sentiment'])\n",
    "\n",
    "# Initialize Logistic Regression classifier\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Initialize RFE with the classifier and the number of desired features\n",
    "num_features_to_select = 15  # Change this value as needed\n",
    "rfe = RFE(classifier, n_features_to_select=num_features_to_select)\n",
    "\n",
    "# Fit RFE to the data\n",
    "rfe.fit(X_cat, Y)\n",
    "\n",
    "# Get the ranking of features\n",
    "feature_ranking = rfe.ranking_\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_cat.columns[rfe.support_]\n",
    "\n",
    "# Print the ranking of features and selected features\n",
    "print(\"Feature Ranking:\")\n",
    "for feature, rank in zip(X_cat.columns, feature_ranking):\n",
    "    print(f\"{feature}: {rank}\")\n",
    "\n",
    "print(\"\\nSelected Features:\")\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginial 134\n",
      "reduced 15\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_selection import chi2, SelectKBest\n",
    "# \n",
    "# # Assuming 'df' is your DataFrame and 'Y' is your target variable\n",
    "# \n",
    "# \n",
    "# # Extract the target variable 'sentiment'\n",
    "# Y = df['sentiment']\n",
    "# \n",
    "# # Drop the 'textID' column from the feature DataFrame\n",
    "# X_cat = df.drop(columns=['textID', 'sentiment'])\n",
    "# \n",
    "# # Initialize SelectKBest with chi-squared as the scoring function\n",
    "# chi2_features = SelectKBest(score_func=chi2, k = 15)\n",
    "# \n",
    "# # Fit SelectKBest to the data and transform it\n",
    "# X_cat_kbest = chi2_features.fit_transform(X_cat, Y)\n",
    "# # \n",
    "# \n",
    "# \n",
    "# print('orginial', X_cat.shape[1])\n",
    "# print('reduced', X_cat_kbest.shape[1])"
   ],
   "metadata": {},
   "id": "16aa62a7-3dda-453b-9c48-75a02a8f953a",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c970585ca23e8ea2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T15:58:43.079688Z",
     "start_time": "2024-02-20T15:58:42.962638Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fisher_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Assuming your dictionary is named 'feature_scores' and your DataFrame is named 'df'\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Filter keys based on score threshold\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m selected_features \u001B[38;5;241m=\u001B[39m [key \u001B[38;5;28;01mfor\u001B[39;00m key, score \u001B[38;5;129;01min\u001B[39;00m \u001B[43mfisher_scores\u001B[49m\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m score \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.02\u001B[39m]\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Drop columns from DataFrame that are not in selected features\u001B[39;00m\n\u001B[1;32m      7\u001B[0m df \u001B[38;5;241m=\u001B[39m df[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtextID\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m selected_features]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'fisher_scores' is not defined"
     ]
    }
   ],
   "source": [
    "# # Assuming your dictionary is named 'feature_scores' and your DataFrame is named 'df'\n",
    "# \n",
    "# # Filter keys based on score threshold\n",
    "# selected_features = [key for key, score in fisher_scores.items() if score >= 0.02]\n",
    "# \n",
    "# # Drop columns from DataFrame that are not in selected features\n",
    "# df = df[['textID', 'sentiment'] + selected_features]\n",
    "# \n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49aeb34e-cc21-4293-93e4-eaf1ed331ef4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T16:02:13.060566Z",
     "start_time": "2024-02-20T16:02:13.045672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values:\n",
      "[]\n",
      "Rows with NaN values:\n",
      "Empty DataFrame\n",
      "Columns: [textID, sentiment, gender, email_verified, blue_tick, normalized_message_length, normalized_num_messages_sent, normalized_follower_count, normalized_following_count, normalized_seniority, normalized_average_time_difference, normalized_follower_following_diff, email_ending_Unknown, email_ending_com, email_ending_de, email_ending_edu, email_ending_gov, email_ending_il, email_ending_jp, email_ending_ke, email_ending_org, email_ending_ru, embedded_content_False, embedded_content_jpeg, embedded_content_link, embedded_content_mp4, platform_facebook, platform_instagram, platform_telegram, platform_tiktok, platform_whatsapp, platform_x, message_time_Evening, message_time_Morning, message_time_Night, message_time_Noon, after, again, an, as, awesom, bad, bed, been, best, better, bit, by, cant, come, cool, could, did, didn, dont, down, enjoy, even, ever, final, follow, friend, fun, girl, gonna, guy, haha, has, hate, he, her, here, him, home, how, hurt, if, last, ll, lol, long, man, mom, more, morn, need, new, next, nice, off, oh, onli, or, over, peopl, right, sad, say, school, she, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 136 columns]\n"
     ]
    }
   ],
   "source": [
    "# # Check for NaN values in each column\n",
    "# nan_columns = df.columns[df.isna().any()].tolist()\n",
    "# print(\"Columns with NaN values:\")\n",
    "# print(nan_columns)\n",
    "# \n",
    "# # Check for NaN values in each row\n",
    "# nan_rows = df[df.isna().any(axis=1)]\n",
    "# print(\"Rows with NaN values:\")\n",
    "# print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62c3c8a5-3dfb-4b53-b013-729be61152d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T14:19:39.114533Z",
     "start_time": "2024-02-20T14:19:37.360110Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9858686616791354\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import pandas as pd\n",
    "# \n",
    "# # Assuming 'df' is your DataFrame with features and target variable\n",
    "# \n",
    "# # Splitting the data into features (X) and target variable (y)\n",
    "# X = df.drop(columns=['sentiment', 'textID'])\n",
    "# y = df['sentiment']\n",
    "# \n",
    "# # Splitting the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# \n",
    "# # Initialize the logistic regression model\n",
    "# model = LogisticRegression()\n",
    "# \n",
    "# # Initialize RFE with the logistic regression model and number of features to select\n",
    "# rfe = RFE(estimator=model, n_features_to_select=5, step=1)\n",
    "# \n",
    "# # Fit RFE to the training data\n",
    "# rfe.fit(X_train, y_train)\n",
    "# \n",
    "# # Get the selected features\n",
    "# selected_features = X.columns[rfe.support_]\n",
    "# \n",
    "# # Train the model using only selected features\n",
    "# model.fit(X_train[selected_features], y_train)\n",
    "# \n",
    "# # Make predictions on the testing set\n",
    "# y_pred = model.predict(X_test[selected_features])\n",
    "# \n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d74e5513-7fff-4fb5-8912-db37b28d949e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-20T16:08:27.734242Z",
     "start_time": "2024-02-20T16:08:27.698460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9850374064837906\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# \n",
    "# # Assuming 'df' is your DataFrame and 'target_column' is your target variable\n",
    "# \n",
    "# # Splitting the data into features (X) and target variable (y)\n",
    "# X = selected_df.drop(columns=['sentiment', 'textID', 'normalized_follower_following_diff'])\n",
    "# y = selected_df['sentiment']\n",
    "# \n",
    "# # Splitting the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# \n",
    "# # Initialize the logistic regression model\n",
    "# model = LogisticRegression()\n",
    "# \n",
    "# # Initialize RFE with the logistic regression model and desired number of features to select\n",
    "# rfe = RFE(estimator=model, n_features_to_select=24)  # Change the number of features as desired\n",
    "# \n",
    "# # Fit RFE to the training data\n",
    "# rfe.fit(X_train, y_train)\n",
    "# \n",
    "# # Get the selected features\n",
    "# selected_features = X.columns[rfe.support_]\n",
    "# \n",
    "# # Train the model on selected features\n",
    "# model.fit(X_train[selected_features], y_train)\n",
    "# \n",
    "# # Make predictions on the testing set\n",
    "# y_pred = model.predict(X_test[selected_features])\n",
    "# \n",
    "# # Calculate accuracy\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991cd077-44fc-42f5-9e07-f7f34cae1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression  # Import your model here\n",
    "\n",
    "# Assuming 'df' is your DataFrame with features and target variable\n",
    "# X should contain the features and Y should contain the target variable\n",
    "# Replace 'target_column' with the name of your target variable column\n",
    "Y = df['target_column']\n",
    "X = df.drop(columns=['target_column'])\n",
    "\n",
    "# Initialize your model\n",
    "model = LogisticRegression()  # Initialize your model here\n",
    "\n",
    "# Define the number of folds (k) for cross-validation\n",
    "num_folds = 5  # You can change this value as needed\n",
    "\n",
    "# Initialize KFold with the number of folds and random state for reproducibility\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "scores = cross_val_score(model, X, Y, cv=kf)\n",
    "\n",
    "# Print the cross-validation scores for each fold\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "\n",
    "# Calculate and print the average cross-validation score\n",
    "average_score = scores.mean()\n",
    "print(\"Average cross-validation score:\", average_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
